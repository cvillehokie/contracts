fit<-train(CompressiveStrength ~ ., data=training, method="lasso")
?train
fit<train(training, mixtures, "lasso", metric="RMSE")
fit<-train(training, mixtures, "lasso", metric="RMSE")
install.packages("elacticnet")
library(elasticnet)
?enet
?plot.enet
?enet
fit<-train(training$CompressiveStrength, training, "lasso", metric="RMSE")
enet()
fit<-train(training$CompressiveStrength, training, "lasso", metric="RMSE")
metric="RMSE"
fit<-train(training$CompressiveStrength~., data=training, method="lasso", metric="RMSE")
fit<-train(training$CompressiveStrength~., data=training, method="lasso")
fit<-train(CompressiveStrength~., data=training, method="lasso")
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
fit<-train(CompressiveStrength ~ ., data=training, method="lasso")
source('~/.active-rstudio-document')
pred<-predict(fit, testing)
plot.enet(fit$finalModel, use.color=T)
str(ft)
str(fit)
dat = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv")
View(dat)
source('~/.active-rstudio-document')
?bats
str(dat)
?training
str(training)
fit<-bats(tstrain)
library(forecast)
install.packages("forecast")
?bats
bats()
library(forecast)
bats()
?bats
fit<-bats(tstrain)
pred <- forecast(fit)
pred$coef
str(pred)
plot(pred)
View(training)
View(testing)
?forecast
remdata<-dat[year(dat$date) >2011]
remdata<-dat[year(dat$date) >2011,]
accuracy(pred, remdata$visitsTumblr)
sum(remdata$visitsTumblr <= pred $upper) / nrow(remdata)
sum(remdata$visitsTumblr <= pred$upper) / nrow(remdata)
remdata = dat[year(dat$date) > 2011,]
tsrem = ts(remdata$visitsTumblr)
model = bats(tstrain)
pred <- forecast(model, h=length(tsrem),level=c(95))
accuracy(pred, remdata$visitsTumblr)
acc = sum(remdata$visitsTumblr <= pred$upper) / nrow(remdata)
acc
?svm
install.packages("e1071")
install.packages("e1071")
install.packages("e1071")
library(e1701)
library(e1071)
?svm
fit<-svm(CompressiveStrength ~ ., data=training)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
pred <- predict(svm, testing)
pred <- predict(fit, testing)
pred
str(pred)
predict - testing$CompressiveStrength
colnames(pred)
summary(pred)
RMSE<-sqrt(mean((testing$CompressiveStrength-predict)^2))
pred <- predict(fit, testing)
nrows(predict)
numrows
nrow
nrow(pred)
ncol(pred)
pred
accuracy(pred, testing$CompressiveStrength)
source('~/.active-rstudio-document')
??accuracy()
library(forecast)
?accuracy
accuracy(pred, testing$CompressiveStrength)
accuracy(pred, testing$CompressiveStrength)$RMSE
acc<-accuracy(pred, testing$CompressiveStrength)$RMSE
str()
acc<-accuracy(pred, testing$CompressiveStrength)
str(acc)
str[RMSE]
acc$RMSE
str["RMSE"]
table(acc)
acc["RMSE"]
acc[RMSE]
install.packages("shiny")
library(shiny)
getwd()
shinyUI(pageWidthSidebar(headerPanel("Data science FTW!"),siderbarPanel(h3('Sidebar text')), mainPanel(h3('Main Panel text'))))
shinyUI(pageWithSidebar(headerPanel("Data science FTW!"),siderbarPanel(h3('Sidebar text')), mainPanel(h3('Main Panel text'))))
shinyUI(pageWithSidebar(headerPanel("Data science FTW!"),sidebarPanel(h3('Sidebar text')), mainPanel(h3('Main Panel text'))))
runApp()
runApp()
runApp()
runApp()
diabetesRisk<-function(glucose) glucose /200
function(input,output) {
output$inputvalue <- renderPrint({input$glucose})
output$Prediction <- renderPrint({diabetesRisk(input$glucose)})
}
)
shinyServer(
function(input,output) {
output$inputvalue <- renderPrint({input$glucose})
output$Prediction <- renderPrint({diabetesRisk(input$glucose)})
}
)
hinyUI(
pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
numericInput('glucose','Glucose mg/dl', 90, min=50, max=200, step=5),
submitButton('Submit')
),
mainPanel(
h3('Main Panel text'),
h4('You entered'),
verbatimTextOutput("inputValue"),
h4('Which result in a prediction of '),
verbatimTextOutput("prediction")
)
)
)
shinyUI(
pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
numericInput('glucose','Glucose mg/dl', 90, min=50, max=200, step=5),
submitButton('Submit')
),
mainPanel(
h3('Main Panel text'),
h4('You entered'),
verbatimTextOutput("inputValue"),
h4('Which result in a prediction of '),
verbatimTextOutput("prediction")
)
)
)
shinyUI(
pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
numericInput('glucose','Glucose mg/dl', 90, min=50, max=200, step=5),
submitButton('Submit')
),
mainPanel(
h3('Main Panel text'),
h4('You entered'),
verbatimTextOutput("inputValue"),
h4('Which result in a prediction of '),
verbatimTextOutput("prediction")
)
)
)
runApp()
library(Rtools)
install.package("Rtools")
install.packages("Rtools")
version()
?
r
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot, s = slider(0, 2, step = 0.1))
library(rCharts)
install.packages("rCharts")
install.packages("airquality")
head(airquality)
dTable(airquality, sPaginationType = "full_numbers")
d <- data.frame(airquality, stringsAsFactors = FALSE) print(d)
d <- data.frame(airquality, stringsAsFactors = FALSE)
View(d)
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar')
),
mainPanel(
h3('Main Panel text')
)
))
runApp("my_app")
runApp()
runApp()
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
libary(devtools)
library(devtools)
require(devtools)
install_github('rCharts','ramnathv')
dTable(airquality, sPaginationType = "full_numbers")
d <- data.frame(airquality, stringsAsFactors = FALSE) print(d)
d <- data.frame(airquality, stringsAsFactors = FALSE)
print(d)
install.packages("dTable")
library(dTable)
getwd()
runApp('stockVis')
library(shiny)
runApp('stockVis')
install.packages("quantmod")
runApp('stockVis')
runApp('stockVis')
shiny::runApp('stockVis')
library(manipulate)
manipulate(plot(1:x), x=slider(1,100))
require(rCharts)
shiny::runApp('stockVis')
library(Fruits)
library(fruits)
data(fruits)
data(fruit)
library(UsingR)
data(fruit)
data(fruits)
library(fruits)
library("Fruits")
data(Fruits)
data("Fruits")
Fruits
devtools::install_github('rstudio/shinyapps')
install.packages("Rtools")
install.packages("Rtools")
package ‘Rtools’ is not available (as a binary package for R version 3.1.3)
install.packages("installr");
updateR()
library(installr)
updateR
updateR()
library(devtools)
find_rtools()
shinyapps::setAccountInfo(name='cvillehokie',
token='1D5F94BD34C9F3C898C5D0E10876A874',
secret='UXpJU1TAvAfTukZ8oDLVj9LXyhLYh5vnWE32p16L')
library(shinyapp)
library(shinyapps)
getwd()
shinyapps::deployApp('census-app')
install.packages(c("shiny","maps","mapproj"))
shinyapps::deployApp('census-app')
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
install.packages("twitteR")
?twitteR
library(twitteR)
?twitteR
user<-getUser('chuckF')
setup_twitter_oauth("F7NyvpfHq2794ar3EYDqfQLEK","ZS3ZpbDk16qb9sxCWGkHZTFiYmMfi6TEoDa35vRxtZ8R5kSuVf" )
setup_twitter_oauth("F7NyvpfHq2794ar3EYDqfQLEK","ZS3ZpbDk16qb9sxCWGkHZTFiYmMfi6TEoDa35vRxtZ8R5kSuVf" )
showStatus9)
showStatus())
showStatus()
check_id("chuckf")
searchTwitter("vegan")
get_twitter_oauth("F7NyvpfHq2794ar3EYDqfQLEK","ZS3ZpbDk16qb9sxCWGkHZTFiYmMfi6TEoDa35vRxtZ8R5kSuVf" )
setup_twitter_oauth("F7NyvpfHq2794ar3EYDqfQLEK","ZS3ZpbDk16qb9sxCWGkHZTFiYmMfi6TEoDa35vRxtZ8R5kSuVf", "11799642-WxAwSUezl9ePh7qJHFkHD4SDrkfSAnDRsx3HtYSsH", "XgwriyS2iPkW7IMpCMHh5hfIg4wwSr50PHoRXZvm1xnjQ")
1
searchTwitter("vegan")
tweets<-searchTwitter("#vegan")
tweets<-searchTwitter("#vegan", n=1000)
?sort()
sort(tweets$favoriteCount)
head(tweet)
head(tweets)
table()
?table()
table(tweets$favoriteCount, tweets$retweetCount)
my<-data.frame(tweets)
my<- as.data.frame(tweets)
unclass(tweets)
df<-do.call("rbind",lapply(tweets, as.data.frame))
View(df)
df["favorited"]
df$favoriteCount>0
df[df$favoriteCount>0]
df[df$favoriteCount>0.]
df[,df$favoriteCount>0]
df[df$favoriteCount>0,]
df2<-df[df$favoriteCount>0,]
View(df2)
df3<-df[df$retweetCount>0,]
df3<-df[df2$retweetCount>0,]
df3<-df2[df2$retweetCount>0,]
View(df3)
intersect()
intersect(df3)
?reduce()
strsplit(df3$text)
strsplit(df3$text, " ")
terms<-strsplit(df3$text, " ")
sort(terms)
str(terms)
?unlist()
me<-unlist(terms)
table(me)
?table
head(able(me))
head(table(me))
all_tweets<-do.call("rbind",lapply(searchTwitter("#vegan", n=5000), as.data.frame))
favorited_tweets <- df[df$favoriteCount>0,]
favorited_tweets <- all_tweets[all_tweets$favoriteCount>0,]
working_tweets <- favorited_tweets[favorited_tweets$retweetCount>0,]
terms<-strsplit(working_tweets$text, " ")
tabulate(terms)
tabulate(unlist(terms))
count(terms
)
library(plyr)
count(terms
)
count(unlist(terms))
head(sort(count(unlist(terms))))
sort(count(unlist(terms)))
count(unlist(terms))
tweets<-strsplit(working_tweets$text, " ")
all_terms <-unlist(terms)
all_terms <-unlist(terms)
counted <- count(all_terms)
View(counted)
sort(counted$freq)
head(sort(counted$freq))
?sort()
head(sort(counted$freq), decreasing=TRUE)
head(sort(counted$freq, decreasing=TRUE))
sorted <- sort(counted$freq, decreasing=TRUE)
?order
?sort()
sort(count)
sort(count$freq)
sort(counted$freq)
sort(count)sort(counted$freq, decreasing=TRUE)
sort(counted$freq, decreasing=TRUE)
all_terms
count(all_terms)
str(all_terms)
install.packages("stringr")
install.packages("stringr")
install.packages("stringr")
library(stringr)
library(twitteR)
str_count(all_terms)
?str_count
str_count(all_terms)
install.packages('tm')
library(tm)
mydata.corpus <- Corpus(VectorSource(allterms))
mydata.corpus <- Corpus(VectorSource(all_terms))
# make each letter lowercase
mydata.corpus <- tm_map(mydata.corpus, tolower)
# remove punctuation
mydata.corpus <- tm_map(mydata.corpus, removePunctuation)
# remove generic and custom stopwords
my_stopwords <- c(stopwords('english'), 'prolife', 'prochoice')
mydata.corpus <- tm_map(mydata.corpus, removeWords, my_stopwords)
# build a term-document matrix
mydata.dtm <- TermDocumentMatrix(mydata.corpus)
mydata.dtm
mydata.corpus <- tm_map(mydata.corpus, removeWords, my_stopwords)
mydata.dtm <- TermDocumentMatrix(mydata.corpus)
?TermDocumentMatrix
findFreqTerms(all_terms, lowfreq=5)
mydata.corpus <- tm_map(mydata.corpus,content_transformer(tolower))
# remove punctuation
mydata.corpus <- tm_map(mydata.corpus,content_transformer(tolower))
mydata.corpus <- Corpus(VectorSource(all_terms))
# make each letter lowercase
mydata.corpus <- tm_map(mydata.corpus,content_transformer(tolower))
# remove punctuation
mydata.corpus <- tm_map(mydata.corpus, removePunctuation)
mydata.dtm <- TermDocumentMatrix(mydata.corpus)
# inspect the document-term matrix
mydata.dtm
# inspect most popular words
findFreqTerms(mydata.dtm, lowfreq=30)
my_stopwords <- c(stopwords('english'), 'prolife', 'prochoice')
my_stopwords <- c(stopwords('english'), 'vegan', 'veganism', 'vegans')
mydata.corpus <- tm_map(mydata.corpus, removeWords, my_stopwords)
# build a term-document matrix
mydata.dtm <- TermDocumentMatrix(mydata.corpus)
# inspect the document-term matrix
mydata.dtm
# inspect most popular words
findFreqTerms(mydata.dtm, lowfreq=30)
terms<-do.call("rbind",lapply(mydata.dtm), as.data.frame)
terms<-do.call("rbind",lapply(mydata.dtm, as.data.frame))
mydata.dtm
summary(mydata.dtm)
me<- findFreqTerms(mydata.dtm, lowfreq=10)
me
write.table(all_tweets, file="all_tweets.csv")
newf<-read.csv("all_tweets.csv")
getwd9)
getwd()
write.table(all_tweets, file="all_tweets.csv", sep=",")
newf<-read.csv("all_tweets.csv")
newf<-read.csv("all_tweets.csv", quote="")
?read.csv
newf<-read.csv("all_tweets.csv", header=TRUE)
newf<-read.csv("all_tweets.csv", header=TRUE, rownames=1:5000)
newf<-read.csv("all_tweets.csv", header=TRUE, row.names=1:5000)
newf<-read.csv("all_tweets.csv")
View(newf)
newf<-read.csv("all_tweets.csv", header=TRUE)
View(newf)
n <- length(all_tweets)
w
all_tweets<-do.call("rbind",lapply(searchTwitter(searchterm, n=500), as.data.frame))
a
searchterm<-"#vegan"
all_tweets<-do.call("rbind",lapply(searchTwitter(searchterm, n=500), as.data.frame))
setup_twitter_oauth("F7NyvpfHq2794ar3EYDqfQLEK","ZS3ZpbDk16qb9sxCWGkHZTFiYmMfi6TEoDa35vRxtZ8R5kSuVf", "11799642-WxAwSUezl9ePh7qJHFkHD4SDrkfSAnDRsx3HtYSsH", "XgwriyS2iPkW7IMpCMHh5hfIg4wwSr50PHoRXZvm1xnjQ")
all_tweets<-do.call("rbind",lapply(searchTwitter(searchterm, n=500), as.data.frame))
n <- length(all_tweets)
n
myCorpus <- Corpus(VectorSource(all_tweets$text))
myCorpus <- tm_map(myCorpus, tolower)
library(tm)
myCorpus <- Corpus(VectorSource(all_tweets$text))
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, toLower)
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, tolower)
myCorpus <- tm_map(myCorpus, removeWords, my_stopwords)
my_stopwords <- c(stopwords('english'),
'vegan',
'veganism',
'vegans'
)
myCorpus <- tm_map(myCorpus, removeWords, my_stopwords)
dictCorpus <- myCorpus
# stem words in a text document with the snowball stemmers,
# which requires packages Snowball, RWeka, rJava, RWekajars
myCorpus <- tm_map(myCorpus, stemDocument)
install.packages("Snowballc")
install.packages('Snowballc')
install.packages("SnowballC")
library(SnowballC)
dictCorpus <- myCorpus
# stem words in a text document with the snowball stemmers,
# which requires packages Snowball, RWeka, rJava, RWekajars
myCorpus <- tm_map(myCorpus, stemDocument)
# inspect the first three ``documents"
inspect(myCorpus[1:3])
# stem completion
myCorpus <- tm_map(myCorpus, stemCompletion, dictionary=dictCorpus)
setup_twitter_oauth("F7NyvpfHq2794ar3EYDqfQLEK", "ZS3ZpbDk16qb9sxCWGkHZTFiYmMfi6TEoDa35vRxtZ8R5kSuVf", "11799642-WxAwSUezl9ePh7qJHFkHD4SDrkfSAnDRsx3HtYSsH","XgwriyS2iPkW7IMpCMHh5hfIg4wwSr50PHoRXZvm1xnjQ")
library(twitteR)
setup_twitter_oauth("F7NyvpfHq2794ar3EYDqfQLEK", "ZS3ZpbDk16qb9sxCWGkHZTFiYmMfi6TEoDa35vRxtZ8R5kSuVf", "11799642-WxAwSUezl9ePh7qJHFkHD4SDrkfSAnDRsx3HtYSsH","XgwriyS2iPkW7IMpCMHh5hfIg4wwSr50PHoRXZvm1xnjQ")
num<-100000
results <- searchTwitter(searchterm, n=num)
searchterm<-"#vegan"
results <- searchTwitter(searchterm, n=num)
num<-10000
results <- searchTwitter(searchterm, n=num)
mean()
?mean
getwd()
shiny::runApp('vegan-proj')
getwd()
library(shiny)
deployApp("contracts/")
library(shinyapps)
deployApp("contracts/")
setwd("contracts/")
deployApp
deployApp()
shiny.rstudio.com/tutorial/lesson
shinyapps::setAccountInfo(name='cvillehokie',
token='1D5F94BD34C9F3C898C5D0E10876A874',
secret='UXpJU1TAvAfTukZ8oDLVj9LXyhLYh5vnWE32p16L')
deployApp()
library(slidify)
publish(user="cvillehokie", repo="https://github.com/cvillehokie/contracts_slidify.git")
setwd("slidify/")
publish(user="cvillehokie", repo="https://github.com/cvillehokie/contracts_slidify.git")
slidify("Contracts-Pitch.Rpres")
source('~/.active-rstudio-document', echo=TRUE)
Please visit https://class.coursera.org/devdataprod-014 for more information on the class!
slidify("Contracts-Pitch.md")
